{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path= r\"/Users/np10002274373/ineuron/Projects/Housing_project/housing/artifact/data_ingestion/2022-07-25-20-40-17/ingested_data/train/housing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y= df.drop(\"median_house_value\", axis=1), df[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 9), (16512,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        158\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isna().sum() #null values in total_bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column= x.drop(columns= [\"ocean_proximity\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleimputer= SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2146e+02,  3.8520e+01,  2.9000e+01, ...,  2.2370e+03,\n",
       "         7.0600e+02,  2.1736e+00],\n",
       "       [-1.1723e+02,  3.3090e+01,  7.0000e+00, ...,  2.0150e+03,\n",
       "         7.6800e+02,  6.3373e+00],\n",
       "       [-1.1904e+02,  3.5370e+01,  4.4000e+01, ...,  6.6700e+02,\n",
       "         3.0000e+02,  2.8750e+00],\n",
       "       ...,\n",
       "       [-1.2272e+02,  3.8440e+01,  4.8000e+01, ...,  4.5800e+02,\n",
       "         1.7200e+02,  3.1797e+00],\n",
       "       [-1.2270e+02,  3.8310e+01,  1.4000e+01, ...,  1.2080e+03,\n",
       "         5.0100e+02,  4.1964e+00],\n",
       "       [-1.2214e+02,  3.9970e+01,  2.7000e+01, ...,  6.2500e+02,\n",
       "         1.9700e+02,  3.1319e+00]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleimputer.fit_transform(numerical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= simpleimputer.transform(numerical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleimputer.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.51   ,   34.26   ,   29.     , 2119.     ,  433.     ,\n",
       "       1164.     ,  408.     ,    3.54155])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleimputer.statistics_  #if any null value, these values used to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            INLAND\n",
       "1        NEAR OCEAN\n",
       "2            INLAND\n",
       "3        NEAR OCEAN\n",
       "4         <1H OCEAN\n",
       "            ...    \n",
       "16507     <1H OCEAN\n",
       "16508        INLAND\n",
       "16509     <1H OCEAN\n",
       "16510     <1H OCEAN\n",
       "16511        INLAND\n",
       "Name: ocean_proximity, Length: 16512, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer= SimpleImputer(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating custom transformer. every transformer should have at least two methods- fit and transform\n",
    "\n",
    "class FeatureGenerator():\n",
    "    \n",
    "\n",
    "    def __init__(self,strategy= \"median\"):\n",
    "        self.strategy= strategy\n",
    "\n",
    "\n",
    "    def fit(self,X):\n",
    "        self.features= X.columns\n",
    "        self.statistics= []\n",
    "        for column in X.columns:\n",
    "            self.statistics.append(X[column].median())\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self,X):\n",
    "        for idx, column in enumerate(X.columns):\n",
    "            X[column].fillna(self.statistics[idx])\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def fit_transform(self,X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 longitude\n",
      "1 latitude\n",
      "2 housing_median_age\n",
      "3 total_rooms\n",
      "4 total_bedrooms\n",
      "5 population\n",
      "6 households\n",
      "7 median_income\n",
      "8 ocean_proximity\n"
     ]
    }
   ],
   "source": [
    "for idx, columns in enumerate(x.columns):\n",
    "    print (idx, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "#by inheriting TransformerMixin, I don't have to explicitly write fit_transform.\n",
    "#Only requirement for custom transformer- should have fit and transform methods.\n",
    "\n",
    "COLUMN_TOTAL_ROOMS = \"total_rooms\"\n",
    "COLUMN_POPULATION = \"population\"\n",
    "COLUMN_HOUSEHOLDS = \"households\"\n",
    "COLUMN_TOTAL_BEDROOM = \"total_bedrooms\"\n",
    "\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True,\n",
    "                 total_rooms_ix=3,\n",
    "                 population_ix=5,\n",
    "                 households_ix=6,\n",
    "                 total_bedrooms_ix=4, columns=None):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        add_bedrooms_per_room: bool\n",
    "        total_rooms_ix: int index number of total rooms columns\n",
    "        population_ix: int index number of total population columns\n",
    "        households_ix: int index number of  households columns\n",
    "        total_bedrooms_ix: int index number of bedrooms columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.columns = columns\n",
    "            if self.columns is not None:\n",
    "                total_rooms_ix = self.columns.index(COLUMN_TOTAL_ROOMS)\n",
    "                population_ix = self.columns.index(COLUMN_POPULATION)\n",
    "                households_ix = self.columns.index(COLUMN_HOUSEHOLDS)\n",
    "                total_bedrooms_ix = self.columns.index(COLUMN_TOTAL_BEDROOM)\n",
    "\n",
    "            self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "            self.total_rooms_ix = total_rooms_ix\n",
    "            self.population_ix = population_ix\n",
    "            self.households_ix = households_ix\n",
    "            self.total_bedrooms_ix = total_bedrooms_ix\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            room_per_household = X[:, self.total_rooms_ix] / \\\n",
    "                                 X[:, self.households_ix]\n",
    "            population_per_household = X[:, self.population_ix] / \\\n",
    "                                       X[:, self.households_ix]\n",
    "            if self.add_bedrooms_per_room:\n",
    "                bedrooms_per_room = X[:, self.total_bedrooms_ix] / \\\n",
    "                                    X[:, self.total_rooms_ix]\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household, bedrooms_per_room]\n",
    "            else:\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household]\n",
    "#np.c_ is used for concatenation\n",
    "            return generated_feature\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5],\n",
       "       [ 1,  6],\n",
       "       [ 2,  7],\n",
       "       [ 3,  8],\n",
       "       [ 4,  9],\n",
       "       [ 5, 10],\n",
       "       [ 6, 11],\n",
       "       [ 7, 12],\n",
       "       [ 8, 13],\n",
       "       [ 9, 14]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1= np.arange(10)\n",
    "arr2=  np.arange(5,15)\n",
    "\n",
    "np.c_[arr1, arr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline= Pipeline(steps=[('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('feature_generator', FeatureGenerator()),\n",
    "('scaling',StandardScaler())\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_pipeline= Pipeline(steps=[('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "('oneHotEncoder', OneHotEncoder()),\n",
    "('scaling',StandardScaler(with_mean=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(train_file_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_column_name= ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income']\n",
    "\n",
    "cat_column_name= ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing= ColumnTransformer([('num_pipeline', num_pipeline, num_column_name),\n",
    "                                ('cat_pipeline', cat_pipeline, cat_column_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94135046,  1.34743822,  0.02756357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.17178212, -1.19243966, -1.72201763, ...,  0.        ,\n",
       "         0.        ,  2.9869105 ],\n",
       "       [ 0.26758118, -0.1259716 ,  1.22045984, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.5707942 ,  1.31001828,  1.53856552, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.56080303,  1.2492109 , -1.1653327 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.28105026,  2.02567448, -0.13148926, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next time we can use preprocessing.transform(new_dataset)\n",
    "\n",
    "import dill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessing.pkl',\"wb\") as prep_file:\n",
    "    dill.dump(preprocessing, prep_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessing.pkl', \"rb\") as file_obj:\n",
    "    preprocessing_loaded_obj= dill.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the below to load the pickle object and run the feature engineering\n",
    "# preprocessing_loaded_obj.transform(new dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
